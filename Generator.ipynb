{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMWR4LruxVwpfe3lz4+MeDs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J96q4pRyk6Fn","executionInfo":{"status":"ok","timestamp":1754923529195,"user_tz":-120,"elapsed":102315,"user":{"displayName":"flavien romanetti","userId":"00912656879255226774"}},"outputId":"0813a875-40e8-460e-84ee-b36f47727a2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip -q install torch torchvision torchaudio matplotlib numpy"]},{"cell_type":"code","source":["import os, re, glob, math, random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","from matplotlib.animation import FuncAnimation\n","from IPython.display import HTML\n","\n","# =========================================================\n","# 1) Config\n","# =========================================================\n","DATA_DIR    = \"/content/data_npy\"\n","SEQ_LEN     = 60                    # 2s @ 30fps\n","F           = 63                    # 21*3 (x,y,z) for one hand\n","BATCH_SIZE  = 16\n","EPOCHS      = 60\n","LR          = 1e-3\n","HIDDEN      = 256\n","NUM_LAYERS  = 2\n","EMB_DIM     = 64\n","TIME_DIM    = 32\n","SEED        = 42\n","\n","random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Device:\", DEVICE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WcuxgSvqk_Zq","executionInfo":{"status":"ok","timestamp":1754923675420,"user_tz":-120,"elapsed":3792,"user":{"displayName":"flavien romanetti","userId":"00912656879255226774"}},"outputId":"2e06d550-6295-4f91-add2-3721c82f7ace"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n"]}]},{"cell_type":"code","source":["# =========================================================\n","# 2) Utilities: resample, masks, normalization\n","# =========================================================\n","def temporal_resample(seq, target_len):\n","    \"\"\"Linear-resample seq: (T,F)->(target_len,F)\"\"\"\n","    T = seq.shape[0]\n","    if T == target_len:\n","        return seq\n","    idxs = np.linspace(0, T-1, num=target_len)\n","    lo = np.floor(idxs).astype(int)\n","    hi = np.clip(lo+1, 0, T-1)\n","    w  = (idxs - lo)[:, None]\n","    return (1-w)*seq[lo] + w*seq[hi]\n","\n","def make_frame_mask(seq):\n","    \"\"\"1 if frame has any nonzero coord; else 0.\"\"\"\n","    return (np.abs(seq).sum(axis=1) > 0).astype(np.float32)\n","\n","def per_frame_handscale(seq):\n","    \"\"\"Distance wrist(0) <-> index_mcp(5) as size proxy.\"\"\"\n","    coords = seq.reshape(-1, 21, 3)\n","    v = coords[:,0,:] - coords[:,5,:]\n","    d = np.linalg.norm(v, axis=1)\n","    if np.any(d > 0):\n","        med = np.median(d[d>0]); d[d<=1e-6] = med\n","    else:\n","        d[:] = 1.0\n","    return d\n","\n","def scale_normalize(seq):\n","    \"\"\"Divide each frame by its size proxy (per-frame); fallback to per-clip median.\"\"\"\n","    s = per_frame_handscale(seq)\n","    med = np.median(s[s>0]) if np.any(s>0) else 1.0\n","    s[s<=1e-6] = med\n","    return seq / s[:, None]"],"metadata":{"id":"-vw4sHoclCiZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# =========================================================\n","# 3) (Light) Augmentations for training\n","# =========================================================\n","def add_noise(x, std=0.002):\n","    return x + np.random.normal(0, std, x.shape)\n","\n","def time_shift(x, max_shift=5, use_zeros=False):\n","    T = x.shape[0]\n","    shift = np.random.randint(-max_shift, max_shift+1)\n","    if shift == 0: return x\n","    if use_zeros:\n","        if shift > 0:\n","            return np.pad(x, ((shift,0),(0,0)), mode='constant')[:T]\n","        else:\n","            return np.pad(x, ((0,-shift),(0,0)), mode='constant')[-T:]\n","    if shift > 0:\n","        pad = np.repeat(x[:1], shift, axis=0)\n","        return np.concatenate([pad, x], axis=0)[:T]\n","    else:\n","        pad = np.repeat(x[-1:], -shift, axis=0)\n","        return np.concatenate([x, pad], axis=0)[-T:]\n","\n","def random_scale(x, min_scale=0.9, max_scale=1.1):\n","    return x * np.random.uniform(min_scale, max_scale)\n","\n","def temporal_dropout(x, drop_prob=0.05, mode=\"hold\"):\n","    T, F_ = x.shape\n","    keep = np.random.rand(T) > drop_prob\n","    if keep.all(): return x\n","    if mode == \"zeros\":\n","        out = x.copy(); out[~keep] = 0; return out\n","    if mode == \"hold\":\n","        out = x.copy(); last = out[0]\n","        for t in range(T):\n","            if keep[t]: last = out[t]\n","            else: out[t] = last\n","        return out\n","    if mode == \"interp\":\n","        out = x.copy()\n","        idx = np.arange(T)\n","        vidx = idx[keep]\n","        if len(vidx) < 2: return x\n","        for f in range(F_):\n","            out[:, f] = np.interp(idx, vidx, x[keep, f])\n","        return out\n","    return x\n","\n","def rotate_z(x, max_angle=10):\n","    T, F_ = x.shape\n","    pts = x.reshape(T, 21, 3)\n","    theta = np.radians(np.random.uniform(-max_angle, max_angle))\n","    c, s = np.cos(theta), np.sin(theta)\n","    R = np.array([[c,-s,0],[s,c,0],[0,0,1]], dtype=x.dtype)\n","    pts = pts @ R.T\n","    return pts.reshape(T, F_)\n","\n","def augment_sample_train(x):\n","    x = add_noise(x, std=0.002)\n","    x = time_shift(x, max_shift=5, use_zeros=False)\n","    x = random_scale(x, 0.9, 1.1)\n","    x = temporal_dropout(x, drop_prob=0.05, mode=\"hold\")\n","    x = rotate_z(x, max_angle=10)\n","    return x\n","\n","def augment_sample_val(x):\n","    return x  # keep validation clean"],"metadata":{"id":"CT-KNqvQlFO0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# =========================================================\n","# 4) Load data with labels\n","# =========================================================\n","SPLIT_RE = re.compile(r'^(train|val)\\d*$', re.IGNORECASE)\n","\n","def load_data_with_labels(data_dir, seq_len=SEQ_LEN):\n","    files = [f for f in os.listdir(data_dir) if f.endswith(\".npy\")]\n","    if not files:\n","        raise RuntimeError(\"No .npy files found in data_dir\")\n","\n","    # Build label map from filename prefix\n","    from collections import OrderedDict\n","    label_map = OrderedDict()\n","    for f in sorted(files):\n","        parts = f[:-4].split(\"_\")\n","        if len(parts) < 2: continue\n","        label = parts[0]\n","        if label not in label_map:\n","            label_map[label] = len(label_map)\n","\n","    # Pass 1: mean/std from TRAIN frames (after normalization)\n","    tmp_train = []\n","    for f in files:\n","        parts = f[:-4].split(\"_\")\n","        if len(parts) < 2: continue\n","        split_raw = parts[1]\n","        if not SPLIT_RE.match(split_raw): continue\n","        arr = np.load(os.path.join(data_dir, f)).astype(np.float32)\n","        arr = temporal_resample(arr, seq_len)\n","        m   = make_frame_mask(arr)\n","        arr = scale_normalize(arr)\n","        if split_raw.lower().startswith(\"train\") and m.sum() > 0:\n","            tmp_train.append(arr[m>0.5])\n","    if not tmp_train:\n","        raise RuntimeError(\"No valid train frames to compute mean/std.\")\n","    cat = np.vstack(tmp_train)\n","    mean = cat.mean(axis=0, keepdims=True)\n","    std  = cat.std(axis=0, keepdims=True) + 1e-6\n","\n","    # Pass 2: load all, standardize, (augment train before norm)\n","    Xtr, Mtr, ytr, fntr = [], [], [], []\n","    Xva, Mva, yva, fnva = [], [], [], []\n","    for f in sorted(files):\n","        parts = f[:-4].split(\"_\")\n","        if len(parts) < 2: continue\n","        label, split_raw = parts[0], parts[1]\n","        if not SPLIT_RE.match(split_raw):\n","            print(f\"Skipping {f}: split not recognized\");\n","            continue\n","\n","        x = np.load(os.path.join(data_dir, f)).astype(np.float32)\n","        x = temporal_resample(x, seq_len)\n","\n","        # augment only train BEFORE mask/normalize/standardize\n","        if split_raw.lower().startswith(\"train\"):\n","            x = augment_sample_train(x)\n","        else:\n","            x = augment_sample_val(x)\n","\n","        m = make_frame_mask(x)\n","        x = scale_normalize(x)\n","        x = (x - mean) / std\n","\n","        if split_raw.lower().startswith(\"train\"):\n","            Xtr.append(x); Mtr.append(m); ytr.append(label_map[label]); fntr.append(f)\n","        else:\n","            Xva.append(x); Mva.append(m); yva.append(label_map[label]); fnva.append(f)\n","\n","    return (np.stack(Xtr), np.stack(Mtr), np.array(ytr), fntr,\n","            np.stack(Xva), np.stack(Mva), np.array(yva), fnva,\n","            label_map, mean, std)\n","\n","# ---- Load now\n","(Xtr, Mtr, ytr, fntr,\n"," Xva, Mva, yva, fnva,\n"," LABEL_MAP, TRAIN_MEAN, TRAIN_STD) = load_data_with_labels(DATA_DIR, SEQ_LEN)\n","\n","print(f\"Classes: {list(LABEL_MAP.keys())}\")\n","print(\"Train:\", Xtr.shape, Mtr.shape, ytr.shape)\n","print(\"Val:  \", Xva.shape, Mva.shape, yva.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"igP5WH0_lIZa","executionInfo":{"status":"ok","timestamp":1754923682235,"user_tz":-120,"elapsed":60,"user":{"displayName":"flavien romanetti","userId":"00912656879255226774"}},"outputId":"b9c776a3-3695-45e8-babf-2f369ed48b10"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Classes: ['find', 'fuck', 'hello', 'home', 'me', 'need', 'no', 'smart', 'thanks', 'yes']\n","Train: (70, 60, 63) (70, 60) (70,)\n","Val:   (20, 60, 63) (20, 60) (20,)\n"]}]},{"cell_type":"code","source":["# =========================================================\n","# 5) Torch datasets\n","# =========================================================\n","class SeqLabelDataset(Dataset):\n","    def __init__(self, X, M, y, fnames):\n","        self.X = torch.from_numpy(X).float()\n","        self.M = torch.from_numpy(M).float()\n","        self.y = torch.from_numpy(y).long()\n","        self.fnames = fnames\n","    def __len__(self): return self.X.shape[0]\n","    def __getitem__(self, i): return self.X[i], self.M[i], self.y[i], self.fnames[i]\n","\n","train_ds = SeqLabelDataset(Xtr, Mtr, ytr, fntr)\n","val_ds   = SeqLabelDataset(Xva, Mva, yva, fnva)\n","train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n","val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, drop_last=False)"],"metadata":{"id":"g0OF8afZlMrR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# =========================================================\n","# 6) Model: Label-conditioned autoregressive LSTM\n","# =========================================================\n","class TimeEmbedding(nn.Module):\n","    def __init__(self, d_model, max_len=1024):\n","        super().__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0)/d_model))\n","        pe[:,0::2] = torch.sin(pos*div)\n","        pe[:,1::2] = torch.cos(pos*div)\n","        self.register_buffer(\"pe\", pe)  # (max_len, d_model)\n","    def forward(self, T):\n","        return self.pe[:T]  # (T,d_model)\n","\n","class CondLSTMGenerator(nn.Module):\n","    \"\"\"\n","    Training (teacher-forcing): input = [prev_frame, label_emb, time_emb] -> predict current frame\n","    Inference (generate): feed zeros (or seed) as prev, roll out T steps for a label\n","    \"\"\"\n","    def __init__(self, F=63, num_classes=10, emb_dim=64, time_dim=32, hidden=256, layers=2):\n","        super().__init__()\n","        self.F = F\n","        self.label_emb = nn.Embedding(num_classes, emb_dim)\n","        self.time_emb  = TimeEmbedding(time_dim, max_len=2048)\n","        self.in_lin    = nn.Linear(F + emb_dim + time_dim, hidden)\n","        self.lstm      = nn.LSTM(hidden, hidden, num_layers=layers, batch_first=True)\n","        self.out_lin   = nn.Linear(hidden, F)\n","\n","    def forward_teacher_forcing(self, x, y_labels):\n","        \"\"\"\n","        x: (B,T,F) ground truth standardized sequence\n","        y_labels: (B,) label indices\n","        returns preds: (B,T,F)\n","        \"\"\"\n","        B,T,F = x.shape\n","        lab = self.label_emb(y_labels)           # (B,emb)\n","        lab = lab[:,None,:].expand(B,T,-1)       # (B,T,emb)\n","        te  = self.time_emb(T)[None,:,:].expand(B,-1,-1)  # (B,T,time)\n","\n","        # teacher forcing: prev = shifted gt, first prev = zeros\n","        x_prev = torch.zeros_like(x)\n","        x_prev[:,1:,:] = x[:,:-1,:]\n","\n","        h_in = torch.cat([x_prev, lab, te], dim=-1)  # (B,T,F+emb+time)\n","        h = self.in_lin(h_in)\n","        h,_ = self.lstm(h)\n","        pred = self.out_lin(h)                        # (B,T,F)\n","        return pred\n","\n","    @torch.no_grad()\n","    def generate(self, y_labels, T, device, start_frame=None):\n","        \"\"\"\n","        y_labels: (B,)\n","        T: int length\n","        start_frame: optional (B,F) seed; else zeros\n","        returns: (B,T,F)\n","        \"\"\"\n","        B = y_labels.shape[0]\n","        lab = self.label_emb(y_labels).to(device)       # (B,emb)\n","        te  = self.time_emb(T).to(device)               # (T,time)\n","        state = None\n","        if start_frame is None:\n","            prev = torch.zeros(B, 1, self.F, device=device)\n","        else:\n","            prev = start_frame[:,None,:].to(device)\n","\n","        outs = []\n","        for t in range(T):\n","            lab_t = lab[:,None,:]                      # (B,1,emb)\n","            te_t  = te[t].expand(B,1,-1)               # (B,1,time)\n","            h_in  = torch.cat([prev, lab_t, te_t], dim=-1)  # (B,1,F+emb+time)\n","            h0    = self.in_lin(h_in)\n","            h1, state = self.lstm(h0, state)\n","            out   = self.out_lin(h1)                   # (B,1,F)\n","            outs.append(out)\n","            prev = out                                 # autoregressive\n","        return torch.cat(outs, dim=1)                  # (B,T,F)\n","\n","def masked_mse(pred, target, mask):\n","    # pred/target: (B,T,F), mask: (B,T)\n","    diff = (pred - target)**2\n","    diff = diff.mean(dim=-1)      # (B,T)\n","    diff = diff * mask\n","    denom = mask.sum(dim=1) + 1e-6\n","    return (diff.sum(dim=1)/denom).mean()\n","\n","# Instantiate model\n","num_classes = len(LABEL_MAP)\n","model = CondLSTMGenerator(F=F, num_classes=num_classes, emb_dim=EMB_DIM, time_dim=TIME_DIM,\n","                          hidden=HIDDEN, layers=NUM_LAYERS).to(DEVICE)\n","optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n"],"metadata":{"id":"AdEnEplblQmJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# =========================================================\n","# 7) Training loop (teacher forcing)\n","# =========================================================\n","def run_epoch(loader, train=True):\n","    model.train(train)\n","    total = 0.0; n = 0\n","    for x, m, y, _ in loader:\n","        x = x.to(DEVICE); m = m.to(DEVICE); y = y.to(DEVICE)\n","        pred = model.forward_teacher_forcing(x, y)\n","        loss = masked_mse(pred, x, m)\n","        if train:\n","            optimizer.zero_grad()\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            optimizer.step()\n","        total += loss.item() * x.size(0); n += x.size(0)\n","    return total / max(1, n)\n","\n","best_val = float(\"inf\")\n","for epoch in range(1, EPOCHS+1):\n","    tr = run_epoch(train_loader, True)\n","    va = run_epoch(val_loader, False)\n","    print(f\"Epoch {epoch:03d} | train {tr:.5f} | val {va:.5f}\")\n","    if va < best_val:\n","        best_val = va\n","        torch.save({\n","            \"model_state\": model.state_dict(),\n","            \"mean\": TRAIN_MEAN,\n","            \"std\":  TRAIN_STD,\n","            \"label_map\": LABEL_MAP,\n","            \"config\": dict(F=F, SEQ_LEN=SEQ_LEN, HIDDEN=HIDDEN, NUM_LAYERS=NUM_LAYERS,\n","                           EMB_DIM=EMB_DIM, TIME_DIM=TIME_DIM)\n","        }, \"cond_gen.pt\")\n","        print(\"  ↳ saved cond_gen.pt\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hHGPGO0KlUKb","executionInfo":{"status":"ok","timestamp":1754923740164,"user_tz":-120,"elapsed":4829,"user":{"displayName":"flavien romanetti","userId":"00912656879255226774"}},"outputId":"9dadf67a-2577-452b-d061-43d8806787b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 001 | train 0.96582 | val 0.77291\n","  ↳ saved cond_gen.pt\n","Epoch 002 | train 0.61597 | val 0.47398\n","  ↳ saved cond_gen.pt\n","Epoch 003 | train 0.46940 | val 0.37039\n","  ↳ saved cond_gen.pt\n","Epoch 004 | train 0.37960 | val 0.32178\n","  ↳ saved cond_gen.pt\n","Epoch 005 | train 0.32477 | val 0.27312\n","  ↳ saved cond_gen.pt\n","Epoch 006 | train 0.27776 | val 0.24335\n","  ↳ saved cond_gen.pt\n","Epoch 007 | train 0.24320 | val 0.22809\n","  ↳ saved cond_gen.pt\n","Epoch 008 | train 0.21918 | val 0.20538\n","  ↳ saved cond_gen.pt\n","Epoch 009 | train 0.19882 | val 0.18622\n","  ↳ saved cond_gen.pt\n","Epoch 010 | train 0.18312 | val 0.17671\n","  ↳ saved cond_gen.pt\n","Epoch 011 | train 0.16901 | val 0.16218\n","  ↳ saved cond_gen.pt\n","Epoch 012 | train 0.15653 | val 0.15251\n","  ↳ saved cond_gen.pt\n","Epoch 013 | train 0.15060 | val 0.15236\n","  ↳ saved cond_gen.pt\n","Epoch 014 | train 0.14913 | val 0.13865\n","  ↳ saved cond_gen.pt\n","Epoch 015 | train 0.13979 | val 0.12966\n","  ↳ saved cond_gen.pt\n","Epoch 016 | train 0.13653 | val 0.12522\n","  ↳ saved cond_gen.pt\n","Epoch 017 | train 0.13164 | val 0.12511\n","  ↳ saved cond_gen.pt\n","Epoch 018 | train 0.12298 | val 0.11568\n","  ↳ saved cond_gen.pt\n","Epoch 019 | train 0.11808 | val 0.12095\n","Epoch 020 | train 0.11676 | val 0.10696\n","  ↳ saved cond_gen.pt\n","Epoch 021 | train 0.11155 | val 0.10476\n","  ↳ saved cond_gen.pt\n","Epoch 022 | train 0.10816 | val 0.10721\n","Epoch 023 | train 0.10532 | val 0.09655\n","  ↳ saved cond_gen.pt\n","Epoch 024 | train 0.10237 | val 0.10189\n","Epoch 025 | train 0.10211 | val 0.09306\n","  ↳ saved cond_gen.pt\n","Epoch 026 | train 0.09939 | val 0.10036\n","Epoch 027 | train 0.09662 | val 0.09270\n","  ↳ saved cond_gen.pt\n","Epoch 028 | train 0.09748 | val 0.10226\n","Epoch 029 | train 0.09976 | val 0.08973\n","  ↳ saved cond_gen.pt\n","Epoch 030 | train 0.09568 | val 0.09153\n","Epoch 031 | train 0.09267 | val 0.08496\n","  ↳ saved cond_gen.pt\n","Epoch 032 | train 0.09136 | val 0.08535\n","Epoch 033 | train 0.08870 | val 0.08361\n","  ↳ saved cond_gen.pt\n","Epoch 034 | train 0.08977 | val 0.08851\n","Epoch 035 | train 0.08738 | val 0.08243\n","  ↳ saved cond_gen.pt\n","Epoch 036 | train 0.08766 | val 0.10064\n","Epoch 037 | train 0.09093 | val 0.08430\n","Epoch 038 | train 0.09026 | val 0.09226\n","Epoch 039 | train 0.09082 | val 0.09081\n","Epoch 040 | train 0.08959 | val 0.09111\n","Epoch 041 | train 0.08762 | val 0.07610\n","  ↳ saved cond_gen.pt\n","Epoch 042 | train 0.08640 | val 0.07949\n","Epoch 043 | train 0.08519 | val 0.08235\n","Epoch 044 | train 0.08475 | val 0.08519\n","Epoch 045 | train 0.08261 | val 0.07807\n","Epoch 046 | train 0.08027 | val 0.07838\n","Epoch 047 | train 0.08005 | val 0.08132\n","Epoch 048 | train 0.07868 | val 0.07344\n","  ↳ saved cond_gen.pt\n","Epoch 049 | train 0.07771 | val 0.07608\n","Epoch 050 | train 0.07767 | val 0.07319\n","  ↳ saved cond_gen.pt\n","Epoch 051 | train 0.07729 | val 0.07548\n","Epoch 052 | train 0.07525 | val 0.07385\n","Epoch 053 | train 0.07424 | val 0.07157\n","  ↳ saved cond_gen.pt\n","Epoch 054 | train 0.07338 | val 0.07425\n","Epoch 055 | train 0.07222 | val 0.07069\n","  ↳ saved cond_gen.pt\n","Epoch 056 | train 0.07128 | val 0.07411\n","Epoch 057 | train 0.07086 | val 0.07188\n","Epoch 058 | train 0.07066 | val 0.07384\n","Epoch 059 | train 0.07087 | val 0.07237\n","Epoch 060 | train 0.07081 | val 0.07614\n"]}]},{"cell_type":"code","source":["# =========================================================\n","# 8) Stick-figure animation helpers\n","# =========================================================\n","HAND_CONNECTIONS = [\n","    (0,1),(1,2),(2,3),(3,4),\n","    (0,5),(5,6),(6,7),(7,8),\n","    (0,9),(9,10),(10,11),(11,12),\n","    (0,13),(13,14),(14,15),(15,16),\n","    (0,17),(17,18),(18,19),(19,20)\n","]\n","\n","def unstandardize(seq_norm, mean, std):\n","    return seq_norm * std + mean\n","\n","def _bounds_from_seq(seq_unstd):\n","    coords = seq_unstd.reshape(-1, 21, 3)\n","    xy_all = coords[:,:,:2].reshape(-1,2)\n","    good = ~np.isnan(xy_all).any(axis=1) & ~np.isinf(xy_all).any(axis=1)\n","    xy_all = xy_all[good]\n","    if xy_all.size == 0:\n","        return -1,1,-1,1\n","    xmin, ymin = xy_all.min(axis=0)\n","    xmax, ymax = xy_all.max(axis=0)\n","    pad = 0.1 * max(1e-6, xmax-xmin, ymax-ymin)\n","    return xmin-pad, xmax+pad, ymin-pad, ymax+pad\n","\n","def animate_sequence(seq_unstd, title=\"Hand animation\", mask=None, fps=30, save_path=None):\n","    \"\"\"\n","    seq_unstd: (T,63) UNstandardized\n","    mask: optional (T,) 1=valid 0=invalid; invalid frames are 'held'\n","    \"\"\"\n","    T = seq_unstd.shape[0]\n","    coords = seq_unstd.reshape(T, 21, 3)[:, :, :2]\n","    if mask is not None and len(mask) == T:\n","        coords_filled = coords.copy()\n","        last = coords_filled[0]\n","        for t in range(T):\n","            if mask[t] > 0.5 and np.isfinite(coords_filled[t]).all():\n","                last = coords_filled[t]\n","            else:\n","                coords_filled[t] = last\n","        coords = coords_filled\n","\n","    xmin, xmax, ymin, ymax = _bounds_from_seq(seq_unstd)\n","    fig, ax = plt.subplots()\n","    scat = ax.scatter([], [])\n","    lines = [ax.plot([], [])[0] for _ in HAND_CONNECTIONS]\n","    ax.set_xlim(xmin, xmax); ax.set_ylim(-ymax, -ymin); ax.set_aspect('equal', adjustable='box')\n","\n","    def init():\n","        scat.set_offsets(np.empty((0,2)))\n","        for ln in lines: ln.set_data([], [])\n","        ax.set_title(title)\n","        return (scat, *lines)\n","\n","    def update(t):\n","        xy = coords[t]\n","        scat.set_offsets(np.c_[xy[:,0], -xy[:,1]])\n","        for ln, (a,b) in zip(lines, HAND_CONNECTIONS):\n","            ln.set_data([xy[a,0], xy[b,0]], [-xy[a,1], -xy[b,1]])\n","        ax.set_title(f\"{title}  t={t+1}/{T}\")\n","        return (scat, *lines)\n","\n","    anim = FuncAnimation(fig, update, init_func=init, frames=T, interval=1000/max(1,fps), blit=True)\n","    if save_path:\n","        try:\n","            anim.save(save_path, fps=fps, dpi=120)\n","            plt.close(fig)\n","            print(f\"Saved animation to {save_path}\")\n","        except Exception as e:\n","            print(f\"Saving failed ({e}). Showing inline instead.\")\n","            plt.close(fig); display(HTML(anim.to_jshtml()))\n","    else:\n","        plt.close(fig); display(HTML(anim.to_jshtml()))"],"metadata":{"id":"nuvmd8xFlXOZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# =========================================================\n","# 9) Quick sanity viz: ground truth vs teacher-forced reconstruction\n","#    (optional; useful to see if the model learned something)\n","# =========================================================\n","model.eval()\n","with torch.no_grad():\n","    if len(val_ds) > 0:\n","        x, m, y, fname = val_ds[0]\n","        x = x.unsqueeze(0).to(DEVICE)\n","        pred_tf = model.forward_teacher_forcing(x, y.unsqueeze(0).to(DEVICE)).cpu().numpy()[0]\n","        x_np = x.cpu().numpy()[0]\n","\n","        gt_seq   = unstandardize(x_np, TRAIN_MEAN, TRAIN_STD)\n","        pred_seq = unstandardize(pred_tf, TRAIN_MEAN, TRAIN_STD)\n","\n","        sign_name = fname.split('_')[0]\n","        animate_sequence(gt_seq,   title=f\"GT – {sign_name}\",   mask=m.numpy(), fps=30)\n","        animate_sequence(pred_seq, title=f\"TF Recon – {sign_name}\", mask=m.numpy(), fps=30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Oz_-T9gCMTa60Gf0s0sMTBbyNoiyMANq"},"id":"SsPAF1D-lax-","executionInfo":{"status":"ok","timestamp":1754923769518,"user_tz":-120,"elapsed":8693,"user":{"displayName":"flavien romanetti","userId":"00912656879255226774"}},"outputId":"f28c4138-2e23-49e6-e426-a9f52ccdbbda"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# =========================================================\n","# 10) Pure generation from a LABEL (no keypoint input)\n","# =========================================================\n","inv_label = {v:k for k,v in LABEL_MAP.items()}\n","\n","def generate_sign(sign_name, length=SEQ_LEN, seed_frame=None, fps=30, save_path=None):\n","    \"\"\"Generate a sequence given the sign label, then animate.\"\"\"\n","    if sign_name not in LABEL_MAP:\n","        raise ValueError(f\"Unknown sign '{sign_name}'. Known: {list(LABEL_MAP.keys())}\")\n","    y_lbl = torch.tensor([LABEL_MAP[sign_name]], device=DEVICE)\n","    model.eval()\n","    with torch.no_grad():\n","        if seed_frame is not None:\n","            seed = torch.from_numpy(seed_frame).float().to(DEVICE)\n","        else:\n","            seed = None\n","        gen = model.generate(y_labels=y_lbl, T=length, device=DEVICE, start_frame=seed).cpu().numpy()[0]\n","    gen_unstd = unstandardize(gen, TRAIN_MEAN, TRAIN_STD)\n","    animate_sequence(gen_unstd, title=f\"Generated – {sign_name}\", fps=fps, save_path=save_path)\n","\n","\n","# generate_sign(sign_name=list(LABEL_MAP.keys())[0], length=SEQ_LEN, fps=30)"],"metadata":{"id":"TQumwn2qldWI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# =========================================================\n","# 11) Save & Load helpers\n","# =========================================================\n","def save_checkpoint(path=\"cond_gen.pt\"):\n","    torch.save({\n","        \"model_state\": model.state_dict(),\n","        \"mean\": TRAIN_MEAN,\n","        \"std\":  TRAIN_STD,\n","        \"label_map\": LABEL_MAP,\n","        \"config\": dict(F=F, SEQ_LEN=SEQ_LEN, HIDDEN=HIDDEN, NUM_LAYERS=NUM_LAYERS,\n","                       EMB_DIM=EMB_DIM, TIME_DIM=TIME_DIM)\n","    }, path)\n","    print(f\"Saved to {path}\")\n","\n","def load_checkpoint(path=\"cond_gen.pt\"):\n","    ckpt = torch.load(path, map_location=DEVICE)\n","    cfg = ckpt.get(\"config\", {})\n","    mdl = CondLSTMGenerator(F=cfg.get(\"F\", F),\n","                            num_classes=len(ckpt[\"label_map\"]),\n","                            emb_dim=cfg.get(\"EMB_DIM\", EMB_DIM),\n","                            time_dim=cfg.get(\"TIME_DIM\", TIME_DIM),\n","                            hidden=cfg.get(\"HIDDEN\", HIDDEN),\n","                            layers=cfg.get(\"NUM_LAYERS\", NUM_LAYERS)).to(DEVICE)\n","    mdl.load_state_dict(ckpt[\"model_state\"])\n","    mdl.eval()\n","    print(\"Loaded model.\")\n","    return mdl, ckpt[\"mean\"], ckpt[\"std\"], ckpt[\"label_map\"]\n","\n","# save_checkpoint(\"cond_gen.pt\")\n","# model, TRAIN_MEAN, TRAIN_STD, LABEL_MAP = load_checkpoint(\"cond_gen.pt\")\n","# generate_sign(\"HELLO\", length=SEQ_LEN)"],"metadata":{"id":"chugyhzGlgNp"},"execution_count":null,"outputs":[]}]}